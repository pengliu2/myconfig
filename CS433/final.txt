1.A:

The number of cache misses depends on the values in A[0:255], but it is at least 256.

Let's say all A[i]'s are odd. Then there would be 512 cache misses.


1.B:

The hardware technique can be hardware prefetching. Prefetched blocks are to be put into a new hardware structure, a buffer that can be more quickly accessed than main memory. When a data miss occurs, two blocks are to be loaded from the memory. The requested block is to be put into cache line, and the prefetched block is to be put into the buffer. And when a requested block is in the buffer, a request is sent to prefetch the block next to it.

In our case, the buffer can be two blocks. And it can eliminate most of the compulsory misses. 

1.C:

for (i=0; i<256; i+=1){
    if (odd(A[i])){
       A[i]=A[i]-1;
    }
}

for (i=0; i<256; i+=1){
    if (odd(A[i])){
       A[i+256]=A[i+256]+1;
    }
}

Conflict misses are eliminated. Because in the first loop, there are no address conflicts. And all A[i]'s are in registers.

In the second loop, there are no address conflicts when A[i+256]'s are placed into cache. 


2:

65536 memory requests. A's size is 4x1024*1024, being transferred in 64 bytes each time. 

14221312
when row mod 16 = 0, 4+18=22 to fill the cache. Others, 4+9=13. 

13.5625

3:

No. Usually offset in page is not changed after being mapped.

6


4:
                                SL is 0 if i does a bus transaction     SL is 1 if i does a bus transaction
Current State in proc i         Read by proc i  Write by proc i         Read by proc i  Write by proc i
DE                              DE/NT           DE/NT                   DE/NT           DE/NT
CS                              CS/NT           CS/BU                   CS/NT           CS/BU
NIC                             DE/BR           DE/BR                   CS/BR           CS/BR+BU


        Bus Read by proc j      Bus Update by proc j
DE      CS/PULLSL+PROVL         NA/NA  
CS      CS/PULLSL+PROVL         CS/UPDL
NIC     NIC/NA                  NIC/NA

5:

6.A:
I would use the fetch/increase instruction to implement the first counter. Because there can be race condition if multiple threads are going to apply for the number at the same time.

6.B:
Ordinary loads/stores are enough. Because once the second counter gets a new number, only one thread would be served so there won't be any race condition.

6.C:

        f&i R1, Count1
TRY_AGAIN:
        ld R2, 0(Count2)
        cmp R1, R2
        jne TRY_AGAIN
        add R1, R1, #1
        str R1, 0(Count2)


7:

